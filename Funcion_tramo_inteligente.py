"""
M√ìDULO: Funcion_tramo_inteligente.py

Este m√≥dulo implementa la l√≥gica para identificar y seleccionar de forma inteligente
el tramo m√°s representativo de una serie temporal para su uso en modelos ARMA 
Integra validaciones estad√≠sticas, pruebas de estacionariedad,
interpolaci√≥n selectiva y visualizaci√≥n guiada del tramo seleccionado.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìå FUNCIONALIDADES PRINCIPALES:

1. Selecci√≥n jer√°rquica de tramos representativos:
   - `seleccionar_tramo_inteligente_para_arma()`: Punto de entrada principal. Aplica
     m√∫ltiples criterios (tests estad√≠sticos, estructura PACF, estabilidad) para encontrar
     el tramo m√°s apto.

2. Estrategias de b√∫squeda:
   - `_buscar_por_tests()`: Eval√∫a subseries mediante tests ADF y KPSS + score estructural.
   - `_buscar_por_score()`: Alternativa m√°s laxa, basada solo en la estructura PACF.
   - `_buscar_fallback()`: √öltimo recurso heur√≠stico, basado en estabilidad de media y varianza.

3. Evaluaci√≥n cuantitativa de tramos:
   - `calcular_score()`: Calcula un score combinando calidad estad√≠stica y estructura autoregresiva.
   - `adf_seguro()`, `kpss_seguro()`: Implementaciones robustas de tests de estacionariedad, tolerantes a errores.

4. Interpolaci√≥n controlada:
   - `interpolar_tramos_cortos()`: Interpola tramos breves con NaNs, aplicando un umbral
     m√°ximo y registrando la intervenci√≥n.

5. Registro y trazabilidad de descartes:
   - `registrar_descarte()`: Centraliza y detalla el motivo de descarte de cada subserie.
   - Variables globales: `motivos_descartes`, `motivos_descartes_extendidos`.

6. Visualizaci√≥n y modelado:
   - `mostrar_resultados_modelado()`: Visualiza y documenta el tramo final seleccionado.
   - `ejecutar_modelado_arma()`: Funci√≥n orquestadora que ejecuta todo el flujo de an√°lisis.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RETORNO FINAL:
   - Tramo de serie escogido
"""

# ==============================================================
# üß± 1. LIBRER√çAS EST√ÅNDAR
# ==============================================================

import json
import warnings
from typing import Tuple, Optional, Union, List, Callable, Dict

# ==============================================================
# üì¶ 2. LIBRER√çAS DE TERCEROS
# ==============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from copy import deepcopy
from collections import Counter
from scipy.stats import normaltest
from statsmodels.tsa.stattools import adfuller, kpss, pacf
from statsmodels.stats.diagnostic import het_arch
from statsmodels.tools.sm_exceptions import InterpolationWarning

# ==============================================================
# üì¶ 3. IMPORTS INTERNOS (otros m√≥dulos del proyecto)
# ==============================================================

from Funciones_preanalisis import preguntar_si_no, plot_serie_inicial

# ==============================================================
# ‚öôÔ∏è 4. CONFIGURACI√ìN GLOBAL DESDE CONFIG.PY
# ==============================================================

# ‚îÄ‚îÄ Par√°metros de ventana
from config import (
    MIN_VENTANA, MAX_VENTANA, PASO, STEP_VENTANA,

    # Interpolaci√≥n
    MAX_NULOS_INTERPOLABLES, METODO_INTERPOLACION_RELLENO,

    # Umbrales para evaluaci√≥n de score
    MIN_LARGO_SUBSERIE, MAX_DELTA_MEAN, MAX_DELTA_VAR,

    # PACF
    NLAGS_SCORE_MIN, NLAGS_SCORE_MAX,
    NLAGS_PACF_MINIMO_EFECTIVO, PACF_METHOD,

    # Tests de estacionariedad
    NLAGS_KPSS_DEFAULT, FALLBACK_PVALUE_KPSS,
    AUTO_LAG_ADF_DEFAULT, FALLBACK_PVALUE_ADF,
    CRITERIO_ESTRUCTO_TEST,

    # Umbrales estad√≠sticos generales
    PVALOR_ADF_UMBRAL, PVALOR_KPSS_UMBRAL, MIN_VARIANZA_ADMISIBLE,

    # Motivos de descarte estandarizados
    DESCARTE_SCORE_NAN, DESCARTE_SCORE_VAR_CERO, DESCARTE_SCORE_CORTA,
    DESCARTE_SCORE_ESTADISTICA, DESCARTE_SCORE_PACF_INSUF, DESCARTE_SCORE_PACF_ERROR,
    DESCARTE_SCORE_DIVISION_CERO, DESCARTE_SCORE_DESCONOCIDO,

    DESCARTE_FALLBACK_NAN, DESCARTE_FALLBACK_VAR_CERO, DESCARTE_FALLBACK_DIVISION_CERO,
    DESCARTE_TEST_NAN, DESCARTE_TEST_VAR_CERO, DESCARTE_TEST_PVALORES,
    DESCARTE_TEST_SCORE_CORTA, DESCARTE_TEST_SCORE_ESTADISTICA,
    DESCARTE_TEST_SCORE_PACF_INSUF, DESCARTE_TEST_SCORE_PACF_ERROR,
    DESCARTE_TEST_SCORE_DIVISION_CERO, DESCARTE_TEST_SCORE_DESCONOCIDO,

    # Configuraci√≥n de salida
    NOMBRE_LOG_TRAMO_DEFAULT, INCLUIR_LOG_EXTENDIDO_TRAMO_MODELOS,
    NOMBRE_ARCHIVO_TRAMO, TITULO_GRAFICO_TRAMO,

    # Modo autom√°tico
    MODO_AUTO
)

# ==============================================================
# ‚ö†Ô∏è 5. SUPRIMIR WARNINGS DE INTERPOLACI√ìN DE STATSMODELS
# ==============================================================

warnings.simplefilter("ignore", InterpolationWarning)

# ==============================================================
# üßæ 6. VARIABLES GLOBALES DE TRAZABILIDAD
# ==============================================================
motivos_descartes: List[str] = []
motivos_descartes_extendidos: List[str] = []

def extraer_subserie(
    serie: pd.Series,
    inicio: int,
    ventana: int,
    log_msg: Optional[Callable[[str], None]] = None
) -> pd.Series:
    
    """
    Extrae de forma segura una subserie de longitud fija desde una posici√≥n
    espec√≠fica dentro de una serie temporal de acuerdo a los par√°metros de la funci√≥n, con validaci√≥n de l√≠mites.

    La funci√≥n previene errores comunes asociados a solicitudes fuera de rango:
    - √çndices negativos o fuera de los l√≠mites de la serie.
    - Tama√±os de ventana inv√°lidos.
    - Tramos que se extienden m√°s all√° del final de la serie.

    Par√°metros:
        serie (pd.Series): Serie temporal original desde la cual extraer el tramo.
        inicio (int): √çndice inicial del tramo a extraer (basado en posici√≥n, no en √≠ndice real).
        ventana (int): Longitud del tramo deseado. Debe ser > 0 y respetar los l√≠mites de la serie.
        log_msg (Callable, opcional): Funci√≥n para registrar mensajes o advertencias.

    Retorna:
        pd.Series: Tramo v√°lido extra√≠do. Si los par√°metros no son v√°lidos, retorna una Serie vac√≠a.
    """

    # Validaci√≥n 1: ventana no puede ser nula o negativa
    if ventana <= 0:
        log_msg(f"‚ö†Ô∏è Ventana inv√°lida: {ventana}. Debe ser > 0.")
        return pd.Series(dtype=serie.dtype)

    # Validaci√≥n 2: √≠ndice de inicio fuera del rango permitido
    if inicio < 0 or inicio >= len(serie):
        log_msg(f"‚ö†Ô∏è √çndice de inicio fuera de rango: {inicio}")
        return pd.Series(dtype=serie.dtype)

    # Validaci√≥n 3: tramo solicitado excede el final de la serie
    fin = inicio + ventana
    if fin > len(serie):
        log_msg(f"‚ö†Ô∏è Subserie excede el l√≠mite de la serie: {inicio} ‚Üí {fin}")
        return pd.Series(dtype=serie.dtype)

    # Subserie v√°lida: devolver segmento solicitado
    return serie.iloc[inicio:fin]

def kpss_seguro(
    serie: Union[pd.Series, np.ndarray],
    nlags: str = NLAGS_KPSS_DEFAULT,
    fallback_pvalue: float = FALLBACK_PVALUE_KPSS,
    log_msg: Optional[Callable[[str], None]] = None
) -> float:
    """
    Ejecuta la prueba de estacionariedad KPSS (Kwiatkowski‚ÄìPhillips‚ÄìSchmidt‚ÄìShin)
    , devolviendo un valor de respaldo si ocurre un error.

    Par√°metros:
        serie (Union[pd.Series, np.ndarray]): Serie temporal a analizar.
        nlags (str): Estrategia de selecci√≥n de rezagos ('auto', 'legacy', 'short', 'long').
        fallback_pvalue (float): Valor p por defecto a devolver si el test falla.
        log_msg (Callable, opcional): Funci√≥n para registrar mensajes o errores.

    Retorna:
        float: Valor p del test KPSS o el valor de respaldo si ocurre un error.
    """
    try:
        # Intenta ejecutar el test KPSS sobre la serie
        _, p_value, _, _ = kpss(serie, nlags=nlags)
        return p_value

    except Exception as e:
        # Si falla, registra el error y retorna un valor p alternativo configurable
        log_msg(f"‚ö†Ô∏è KPSS fall√≥ con nlags='{nlags}': {e}")
        return fallback_pvalue

def adf_seguro(
    serie: Union[pd.Series, np.ndarray],
    autolag: str = AUTO_LAG_ADF_DEFAULT,
    fallback_pvalue: float = FALLBACK_PVALUE_ADF,
    log_msg: Optional[Callable[[str], None]] = None
) -> float:
    
    """
    Ejecuta la prueba ADF (Augmented Dickey-Fuller) de forma segura, con tolerancia a errores.

    Par√°metros:
        serie (Union[pd.Series, np.ndarray]): Serie temporal a evaluar.
        autolag (str): Estrategia para seleccionar el n√∫mero √≥ptimo de rezagos
                       ('AIC', 'BIC', 't-stat', etc.).
        fallback_pvalue (float): Valor p a devolver si ocurre un error durante el test.
        log_msg (Callable, opcional): Funci√≥n para registrar errores u observaciones.

    Retorna:
        float: Valor p obtenido del test ADF o el valor de respaldo si se produce una excepci√≥n.
    """

    try:
        # Intenta ejecutar la prueba ADF sobre la serie
        _, p_value, _, _, _, _ = adfuller(serie, autolag=autolag)
        return p_value

    except Exception as e:
        # Si falla, registra el error y devuelve el valor p de respaldo
        log_msg(f"‚ö†Ô∏è ADF fall√≥ con autolag='{autolag}': {e}")
        return fallback_pvalue

def calcular_score(
    subserie: pd.Series,
    serie: pd.Series,
    min_largo: int = MIN_LARGO_SUBSERIE,
    max_delta_mean: float = MAX_DELTA_MEAN,
    max_delta_var: float = MAX_DELTA_VAR,
    min_varianza: float = MIN_VARIANZA_ADMISIBLE,
    nlags_min: int = NLAGS_SCORE_MIN,
    nlags_max: int = NLAGS_SCORE_MAX,
    nlags_pacf_min: int = NLAGS_PACF_MINIMO_EFECTIVO,
    pacf_method: str = PACF_METHOD,
    log_msg: Optional[Callable[[str], None]] = None,
) -> float:
    """
    Eval√∫a la calidad estad√≠stica y estructural de una subserie temporal mediante un score compuesto.

    Este score ponderado combina:
        - Estructura autoregresiva (PACF).
        - Similitud estad√≠stica con la serie completa (media y varianza).
        - Tama√±o relativo respecto a la serie original.

    Si la subserie no es apta por razones estad√≠sticas o t√©cnicas, se devuelve un c√≥digo negativo
    que indica el motivo espec√≠fico del descarte.

    C√≥digos de retorno negativos:
        - -1.0 ‚Üí Subserie demasiado corta.
        - -2.0 ‚Üí Diferencia excesiva en media/varianza, o varianza nula.
        - -3.0 ‚Üí Subserie demasiado corta para PACF efectivo.
        - -4.0 ‚Üí Error al calcular PACF (NaNs o excepci√≥n).
        - -5.0 ‚Üí Divisi√≥n por cero durante normalizaci√≥n del score.

    Par√°metros:
        subserie (pd.Series): Tramo de serie a evaluar.
        serie (pd.Series): Serie original completa.
        min_largo (int): Longitud m√≠nima para aceptar una subserie.
        max_delta_mean (float): Diferencia m√°xima aceptada en medias.
        max_delta_var (float): Diferencia m√°xima aceptada en varianza.
        min_varianza (float): Varianza m√≠nima aceptada para el tramo.
        nlags_min (int): M√≠nimo n√∫mero de lags para PACF.
        nlags_max (int): M√°ximo n√∫mero de lags para PACF.
        nlags_pacf_min (int): Umbral m√≠nimo efectivo de lags √∫tiles.
        pacf_method (str): M√©todo de c√°lculo de PACF (por ejemplo, 'ywunbiased').
        log_msg (Callable, opcional): Funci√≥n de logging para registrar errores o eventos.

    Retorna:
        float:
            - Score positivo ‚Üí subserie v√°lida.
            - Score negativo ‚Üí motivo de descarte codificado.
    """

    # Validaci√≥n de longitud m√≠nima
    if len(subserie) < min_largo:
        log_msg("üî¥ Subserie demasiado corta.")
        return -1.0

    serie = serie.dropna()

    # Comparaci√≥n de media y varianza con la serie completa
    var_sub = subserie.var()
    mean_sub = subserie.mean()
    var_full = serie.var()
    mean_full = serie.mean()

    delta_mean = abs(mean_full - mean_sub)
    delta_var = abs(var_full - var_sub)

    # Validaci√≥n de diferencias y varianza m√≠nima
    if delta_mean > max_delta_mean or delta_var > max_delta_var:
        return -2.0
    if var_sub < min_varianza:
        return -2.0

    # Validaci√≥n de PACF: determinar n√∫mero de lags
    long_sub = len(subserie)
    long_full = len(serie)
    tamano_relativo = long_sub / long_full if long_full else 0.0

    nlags = min(nlags_max, max(nlags_min, long_sub // 10))
    nlags = min(nlags, (long_sub - 1) // 2)

    if nlags < nlags_pacf_min:
        return -3.0

    if subserie.isnull().any():
        return -4.0

    # C√°lculo del score estructural con PACF
    weights = np.linspace(1.0, 0.3, nlags)  # Decrece linealmente
    try:
        pacf_vals = np.abs(pacf(subserie, nlags=nlags, method=pacf_method)[1:nlags + 1])
        pacf_score = np.sum(weights * pacf_vals)
    except Exception:
        return -4.0

    #  C√°lculo final del score normalizado
    denom = 1 + np.sqrt(var_sub) + delta_mean + delta_var
    if denom == 0:
        return -5.0

    score = (pacf_score * tamano_relativo) / denom
    return score

def registrar_descarte(
    motivo: str,
    inicio: Optional[int] = None,
    fin: Optional[int] = None,
    motivos: Optional[List[str]] = None,
    motivos_ext: Optional[List[str]] = None,
    log_msg: Optional[Callable[[str], None]] = None
) -> str:
    """
    Registra un motivo de descarte para un tramo de una serie temporal de acuerdo al c√°lculo del score y las pruebas estad√≠sticas realizadas. 

    Este registro se puede almacenar en dos niveles:
    - üü¢ Motivo simple: solo el texto del motivo (ej. "VARIANZA_CERO")
    - üîµ Motivo extendido: incluye el rango de √≠ndice si est√° disponible (ej. "100:150 VARIANZA_CERO")

    Las listas de descarte pueden ser globales (por defecto) o listas externas pasadas como argumento.

    Par√°metros:
        motivo (str): Texto que describe el motivo del descarte.
        inicio (int, opcional): √çndice de inicio del tramo descartado.
        fin (int, opcional): √çndice final del tramo descartado.
        motivos (List[str], opcional): Lista en la que guardar motivos simples.
        motivos_ext (List[str], opcional): Lista en la que guardar motivos extendidos.
        log_msg (Callable, opcional): Funci√≥n para log (no utilizada actualmente, pero se puede activar).

    Retorna:
        str: Motivo registrado.
    """
    # Se accede a las listas globales si no se pasan listas espec√≠ficas
    global motivos_descartes, motivos_descartes_extendidos

    # Si hay informaci√≥n del tramo (inicio-fin), se a√±ade al motivo para mayor detalle
    if inicio is not None and fin is not None:
        motivo_extendido = f"{inicio}:{fin} {motivo}"
    else:
        motivo_extendido = motivo

    # Se usan listas locales si se pasan, si no, las listas globales
    if motivos is None:
        motivos = motivos_descartes
    if motivos_ext is None:
        motivos_ext = motivos_descartes_extendidos

    # A√±adir motivo simple y extendido a sus respectivas listas
    motivos.append(motivo)
    motivos_ext.append(motivo_extendido)

    return motivo_extendido

def _buscar_por_tests(
    serie: pd.Series,
    prop_ventana: float = MAX_VENTANA,
    prop_ventana_min: float = MIN_VENTANA,
    paso: float = PASO,
    step_ventana: float = STEP_VENTANA,
    pvalor_adf_umbral: float = PVALOR_ADF_UMBRAL,
    pvalor_kpss_umbral: float = PVALOR_KPSS_UMBRAL,
    min_varianza_admisible: float = MIN_VARIANZA_ADMISIBLE,
    criterio_estricto_tests: bool = CRITERIO_ESTRUCTO_TEST,
    log_msg: Optional[Callable[[str], None]] = None,

) -> Tuple[Optional[int], Optional[int], Optional[pd.Series], float, Optional[float], Optional[float], str]:
    """
    Busca el mejor tramo de una serie temporal utilizando pruebas estad√≠sticas (ADF, KPSS)
    y evaluaci√≥n estructural (PACF) Aplicando el enfoque de ventanas m√≥viles.

    El objetivo es encontrar una subserie sin NaNs, con varianza aceptable, que adem√°s
    cumpla con criterios de estacionariedad y estructura autoregresiva significativa.


    Par√°metros:
        serie (pd.Series): Serie temporal original.
        prop_ventana (float): Proporci√≥n inicial del tama√±o de la ventana (ej. 0.3 = 30%).
        prop_ventana_min (float): Proporci√≥n m√≠nima permitida para las ventanas.
        paso (float): Proporci√≥n del total de la serie a desplazar entre ventanas (ej. 0.01 = 1%).
        step_ventana (float): Proporci√≥n del total de la serie que se reducir√° en cada iteraci√≥n de ventana.
        pvalor_adf_umbral (float): Umbral m√°ximo para aceptar estacionariedad seg√∫n ADF.
        pvalor_kpss_umbral (float): Umbral m√°ximo para aceptar estacionariedad seg√∫n KPSS.
        min_varianza_admisible (float): Varianza m√≠nima aceptada para considerar una subserie v√°lida.
        criterio_estricto_tests (bool): Si True, aplica criterio estricto combinando ADF y KPSS.
        log_msg (Callable, opcional): Funci√≥n para imprimir o registrar mensajes del proceso.

    Retorna:
        Tuple[
            Optional[int],       # √çndice inicial del mejor tramo
            Optional[int],       # √çndice final (exclusivo) del mejor tramo
            Optional[pd.Series], # Subserie seleccionada
            float,               # Score calculado del tramo
            Optional[float],     # p-valor ADF
            Optional[float],     # p-valor KPSS
            str                  # M√©todo utilizado ("Test+score")
        ]
    """

    L = len(serie)

    # Convertimos proporciones en valores absolutos (en n√∫mero de observaciones)
    paso = max(1, int(round(L * paso)))
    step_ventana = max(1, int(round(L * step_ventana)))
    min_ventana = max(5, int(round(L * prop_ventana_min)))
    ventana = max(min_ventana + 1, int(round(L * prop_ventana)))

    # Inicializamos variables para guardar el mejor tramo encontrado
    mejor_score = -np.inf
    mejor_subserie = None
    inicio_mejor = None
    fin_mejor = None
    adf_p_mejor = None
    kpss_p_mejor = None

    # Logging de configuraci√≥n inicial

    log_msg("üîç Buscando por TESTS (ADF + KPSS)...")
    log_msg(f"üìê Config ventana: inicial={ventana}, m√≠nima={min_ventana}, paso={paso}, reducci√≥n={step_ventana}")

    # B√∫squeda jer√°rquica: vamos reduciendo la ventana hasta el m√≠nimo permitido
    while ventana >= min_ventana:
        for inicio in range(0, L - ventana, paso):
            fin = inicio + ventana
            subserie = extraer_subserie(serie, inicio, ventana, log_msg=log_msg)

            # Filtro 1: Si hay nulos, descartamos
            if subserie.isna().sum() > 0:
                registrar_descarte(DESCARTE_TEST_NAN, inicio, fin, log_msg=log_msg)
                continue

            # Filtro 2: Si tiene varianza muy baja, descartamos
            if subserie.std() < min_varianza_admisible:
                registrar_descarte(DESCARTE_TEST_VAR_CERO, inicio, fin, log_msg=log_msg)
                continue

            # Pruebas estad√≠sticas ADF y KPSS
            adf_p = adf_seguro(subserie, log_msg=log_msg)
            kpss_p = kpss_seguro(subserie, log_msg=log_msg)

            # Evaluaci√≥n de estacionariedad
            if criterio_estricto_tests:
                if adf_p >= pvalor_adf_umbral or kpss_p <= pvalor_kpss_umbral:
                    registrar_descarte(DESCARTE_TEST_PVALORES, inicio, fin, log_msg=log_msg)
                    continue
            else:
                if adf_p >= pvalor_adf_umbral and kpss_p <= pvalor_kpss_umbral:
                    registrar_descarte(DESCARTE_TEST_PVALORES, inicio, fin, log_msg=log_msg)
                    continue

            # Evaluamos la calidad estructural con un score PACF
            score = calcular_score(subserie, serie, log_msg=log_msg)

            # Si el score es negativo, lo descartamos con su causa
            if score < 0:
                if score == -1.0:
                    registrar_descarte(DESCARTE_TEST_SCORE_CORTA, inicio, fin, log_msg=log_msg)
                elif score == -2.0:
                    registrar_descarte(DESCARTE_TEST_SCORE_ESTADISTICA, inicio, fin, log_msg=log_msg)
                elif score == -3.0:
                    registrar_descarte(DESCARTE_TEST_SCORE_PACF_INSUF, inicio, fin, log_msg=log_msg)
                elif score == -4.0:
                    registrar_descarte(DESCARTE_TEST_SCORE_PACF_ERROR, inicio, fin, log_msg=log_msg)
                elif score == -5.0:
                    registrar_descarte(DESCARTE_TEST_SCORE_DIVISION_CERO, inicio, fin, log_msg=log_msg)
                else:
                    registrar_descarte(DESCARTE_TEST_SCORE_DESCONOCIDO, inicio, fin, log_msg=log_msg)
                continue

            # Guardamos el mejor tramo encontrado hasta ahora
            if score > mejor_score:
                mejor_score = score
                mejor_subserie = subserie
                inicio_mejor = inicio
                fin_mejor = fin
                adf_p_mejor = adf_p
                kpss_p_mejor = kpss_p

        # Si ya tenemos un tramo v√°lido, no reducimos m√°s la ventana
        if mejor_subserie is not None:
            log_msg(f"‚úÖ Tramo TEST encontrado: {inicio_mejor}-{fin_mejor} | Score: {mejor_score:.2f}")
            break

        # Reducimos la ventana y continuamos iterando
        ventana -= step_ventana

    # Retornamos resultado final
    return inicio_mejor, fin_mejor, mejor_subserie, mejor_score, adf_p_mejor, kpss_p_mejor, "Test+score"

def _buscar_por_score(
    serie: pd.Series,
    prop_ventana: float = MAX_VENTANA,
    prop_ventana_min: float = MIN_VENTANA,
    paso: float = PASO,
    step_ventana: float = STEP_VENTANA,
    min_varianza_admisible: float = MIN_VARIANZA_ADMISIBLE,
    log_msg: Optional[Callable[[str], None]] = None
) -> Tuple[Optional[int], Optional[int], Optional[pd.Series], float, None, None, str]:
    """
    Busca un tramo de serie temporal en base √∫nicamente al an√°lisis estructural,
    utilizando un score basado en la funci√≥n de autocorrelaci√≥n parcial (PACF) ponderada.

    Este enfoque act√∫a como fallback cuando no se puede aplicar (o no superan) los tests
    de estacionariedad ADF y KPSS. Se recorren ventanas m√≥viles sobre la serie original,
    evaluando subseries que no contengan valores nulos y que superen una varianza m√≠nima.

    Se selecciona la subserie con mayor score como el mejor tramo candidato.

    Par√°metros:
        serie (pd.Series): Serie temporal original sobre la que buscar el tramo.
        prop_ventana (float): Proporci√≥n inicial del tama√±o de ventana respecto a la longitud total de la serie (ej. 0.3).
        prop_ventana_min (float): Proporci√≥n m√≠nima aceptada para la ventana (ej. 0.05).
        paso (float): Proporci√≥n del tama√±o total de la serie para desplazar la ventana (ej. 0.01 = 1% del total).
        step_ventana (float): Proporci√≥n del tama√±o total de la serie para reducir la ventana en cada iteraci√≥n (ej. 0.01).
        min_varianza_admisible (float): Varianza m√≠nima aceptada para considerar una subserie v√°lida.
        log_msg (Callable | None): Funci√≥n para registrar mensajes durante el proceso. Si None, no se registra nada.

    Retorna:
        Tuple[
            Optional[int],        # √çndice de inicio del tramo seleccionado
            Optional[int],        # √çndice de fin (exclusivo) del tramo seleccionado
            Optional[pd.Series],  # Subserie seleccionada como mejor candidata
            float,                # Score PACF obtenido por la subserie
            None,                 # No aplica test ADF
            None,                 # No aplica test KPSS
            str                   # M√©todo utilizado ("Score")
        ]
    """

    L = len(serie)

    # Convertimos proporciones en valores absolutos
    paso = max(1, int(round(L * paso)))
    step_ventana = max(1, int(round(L * step_ventana)))
    min_ventana = max(5, int(round(L * prop_ventana_min)))
    ventana = max(min_ventana + 1, int(round(L * prop_ventana)))

    # Inicializamos las variables del mejor tramo
    mejor_score = -np.inf
    mejor_subserie = None
    inicio_mejor = None
    fin_mejor = None

    # Log de inicio
    log_msg("üîÅ Fallback parcial: buscando por SCORE (estructura PACF)...")

    # B√∫squeda jer√°rquica descendente de ventana
    while ventana >= min_ventana:
        for inicio in range(0, L - ventana, paso):
            fin = inicio + ventana
            subserie = extraer_subserie(serie, inicio, ventana, log_msg=log_msg)

            # Descartamos si hay nulos
            if subserie.isna().sum() > 0:
                registrar_descarte(DESCARTE_SCORE_NAN, inicio, fin, log_msg=log_msg)
                continue

            # Descartamos si tiene varianza demasiado baja
            if subserie.std() < min_varianza_admisible:
                registrar_descarte(DESCARTE_SCORE_VAR_CERO, inicio, fin, log_msg=log_msg)
                continue

            # üìà Calculamos el score estructural (PACF ponderado)
            score = calcular_score(subserie, serie, log_msg=log_msg)

            # Si el score es negativo, lo descartamos con su causa
            if score < 0:
                motivo = {
                    -1.0: DESCARTE_SCORE_CORTA,
                    -2.0: DESCARTE_SCORE_ESTADISTICA,
                    -3.0: DESCARTE_SCORE_PACF_INSUF,
                    -4.0: DESCARTE_SCORE_PACF_ERROR,
                    -5.0: DESCARTE_SCORE_DIVISION_CERO
                }.get(score, DESCARTE_SCORE_DESCONOCIDO)

                registrar_descarte(motivo, inicio, fin, log_msg=log_msg)
                continue

            # Si mejora el score, guardamos como mejor candidato
            if score >= mejor_score:
                mejor_score = score
                mejor_subserie = subserie
                inicio_mejor = inicio
                fin_mejor = fin

        # Si encontramos uno v√°lido, paramos
        if mejor_subserie is not None:
            log_msg(f"‚úÖ Tramo SCORE elegido: {inicio_mejor} ‚Üí {fin_mejor} | Score: {mejor_score:.3f}")
            break

        # Reducimos tama√±o de ventana y repetimos
        ventana -= step_ventana

    # Resultado final
    return inicio_mejor, fin_mejor, mejor_subserie, mejor_score, None, None, "Score"

def _buscar_fallback(
    serie: pd.Series,
    prop_ventana: float = MAX_VENTANA,
    prop_ventana_min: float = MIN_VENTANA,
    paso: float = PASO,  
    step_ventana: float = STEP_VENTANA, 
    min_varianza_admisible: float = MIN_VARIANZA_ADMISIBLE,
    log_msg: Optional[Callable[[str], None]] = None
) -> Tuple[Optional[int], Optional[int], Optional[pd.Series], float, None, None, str]:
    """
    Estrategia final de respaldo ("fallback") para seleccionar un tramo representativo
    de la serie temporal, si fallan las pruebas ADF, KPSS o estructura PACF.

    Selecciona el tramo cuya media y varianza est√©n m√°s cercanas a la serie completa,
    sin aplicar tests estad√≠sticos ni an√°lisis de autocorrelaci√≥n. Ideal como √∫ltimo recurso.

    Par√°metros:
        serie (pd.Series): Serie temporal original.
        prop_ventana (float): Proporci√≥n m√°xima del tama√±o de ventana (ej. 0.3 = 30%).
        prop_ventana_min (float): Proporci√≥n m√≠nima aceptada del tama√±o de ventana.
        paso (float): Proporci√≥n de desplazamiento entre subseries (ej. 0.01 = 1%).
        step_ventana (float): Proporci√≥n con la que se reduce progresivamente la ventana.
        min_varianza_admisible (float): Varianza m√≠nima para considerar una subserie v√°lida.
        log_msg (Callable, opcional): Funci√≥n de log para registrar pasos e incidencias.

    Retorna:
        Tuple[
            Optional[int],       # √çndice de inicio del mejor tramo
            Optional[int],       # √çndice final (exclusivo)
            Optional[pd.Series], # Subserie seleccionada
            float,               # Score heur√≠stico (m√°s alto es mejor)
            None,                # No aplica ADF
            None,                # No aplica KPSS
            str                  # M√©todo aplicado: "Fallback"
        ]
    """
    # Configuraci√≥n de ventana
    L = len(serie)
    min_ventana = max(5, int(round(L * prop_ventana_min)))
    ventana = max(min_ventana + 1, int(round(L * prop_ventana)))

    media_total = serie.mean()
    var_total = serie.var()

    # Inicializaci√≥n de variables para b√∫squeda
    mejor_score = -np.inf
    mejor_subserie = None
    inicio_mejor = None
    fin_mejor = None

    log_msg(" Fallback final: buscando tramo con media/varianza similar a la serie...")

    # Recorrido de ventanas decrecientes 
    while ventana >= min_ventana:
        desplazamiento = max(1, int(round(L * paso)))  # Convertir proporci√≥n a paso absoluto

        for inicio in range(0, L - ventana + 1, desplazamiento):
            fin = inicio + ventana
            subserie = extraer_subserie(serie, inicio, ventana, log_msg=log_msg)

            # Filtros
            if subserie.isna().sum() > 0:
                registrar_descarte(DESCARTE_FALLBACK_NAN, inicio, fin, log_msg=log_msg)
                continue

            var_sub = subserie.var()
            if var_sub < min_varianza_admisible:
                registrar_descarte(DESCARTE_FALLBACK_VAR_CERO, inicio, fin, log_msg=log_msg)
                continue

            # Heur√≠stica basada en similitud de media y varianza
            media_diff = abs(subserie.mean() - media_total)
            var_diff = abs(var_sub - var_total)
            denominador = media_diff + var_diff

            if denominador < 1e-10:
                registrar_descarte(DESCARTE_FALLBACK_DIVISION_CERO, inicio, fin, log_msg=log_msg)
                continue

            # Score m√°s alto si el tramo es m√°s parecido a la serie global
            score = (L / ventana) / (denominador + 1e-8)

            if score > mejor_score:
                mejor_score = score
                mejor_subserie = subserie
                inicio_mejor = inicio
                fin_mejor = fin

        # Si se encontr√≥ un buen tramo, se detiene la b√∫squeda
        if mejor_subserie is not None:
            log_msg(f"‚úÖ Tramo Fallback elegido: {inicio_mejor}-{fin_mejor} | Score heur√≠stico: {mejor_score:.2f}")
            break

        # Reducir ventana proporcionalmente
        ventana -= int(round(L * step_ventana))

    return inicio_mejor, fin_mejor, mejor_subserie, mejor_score, None, None, "Fallback"

def interpolar_tramos_cortos(
    serie: pd.Series,
    max_huecos: int = MAX_NULOS_INTERPOLABLES,
    metodo: str = METODO_INTERPOLACION_RELLENO,
    log_msg: Optional[Callable[[str], None]] = None
) -> pd.Series:
    """
    Interpola de forma controlada los tramos cortos de NaNs dentro de una serie temporal,
    siempre que la longitud del hueco no supere un umbral especificado.

    Conserva los extremos del hueco para una interpolaci√≥n confiable (requiere valores
    previos y posteriores). Si existen NaNs pero ning√∫n tramo es lo suficientemente
    corto para interpolar, se informa por log.

    Par√°metros:
        serie (pd.Series): Serie temporal original a procesar.
        max_huecos (int): Tama√±o m√°ximo de un hueco (consecutivo) que puede ser interpolado.
        metodo (str): M√©todo de interpolaci√≥n a aplicar (por defecto, 'linear').
        log_msg (Callable, opcional): Funci√≥n para registrar mensajes (compatible con log global).

    Retorna:
        pd.Series: Serie con interpolaciones aplicadas en huecos v√°lidos.
    """
    tramos_interpolados_log = []
    serie_interpolada = serie.copy()
    is_na = serie.isna().tolist()

    if not any(is_na):
        if log_msg:
            log_msg("‚ÑπÔ∏è La serie no contiene valores nulos. No se aplica interpolaci√≥n.")
        return serie_interpolada

    start = None
    for i, es_nan in enumerate(is_na):
        if es_nan and start is None:
            start = i
        elif not es_nan and start is not None:
            fin = i
            longitud = fin - start

            if longitud <= max_huecos and start > 0 and fin < len(serie):
                tramo = serie_interpolada.iloc[start - 1:fin + 1]
                interpolado = tramo.interpolate(method=metodo, limit_direction="both")
                serie_interpolada.iloc[start:fin] = interpolado.iloc[1:-1]

                tramos_interpolados_log.append({
                    "inicio": start,
                    "fin": fin - 1,
                    "longitud": longitud,
                    "metodo": metodo
                })
            start = None

    # Caso especial: hueco al final de la serie
    if start is not None:
        fin = len(serie)
        longitud = fin - start
        if longitud <= max_huecos and start > 0:
            tramo = serie_interpolada.iloc[start - 1:]
            interpolado = tramo.interpolate(method=metodo, limit_direction="both")
            serie_interpolada.iloc[start:] = interpolado.iloc[1:]

            tramos_interpolados_log.append({
                "inicio": start,
                "fin": fin - 1,
                "longitud": longitud,
                "metodo": metodo
            })

    # Registro final
    if log_msg:
        if tramos_interpolados_log:
            log_msg(f"ü©π Interpolados {len(tramos_interpolados_log)} tramo(s) con ‚â§ {max_huecos} NaNs.")
        else:
            log_msg(f"‚ö†Ô∏è Se encontraron NaNs pero ning√∫n tramo era interpolable (>{max_huecos} consecutivos).")

    return serie_interpolada, tramos_interpolados_log

def seleccionar_tramo_inteligente_para_arma(
    serie: pd.Series,
    prop_ventana: float = MAX_VENTANA,
    prop_ventana_min: float = MIN_VENTANA,
    paso: int = PASO,
    step_ventana: int = STEP_VENTANA,
    max_huecos_interpolables: int = MAX_NULOS_INTERPOLABLES,
    metodo_interpolacion: str = METODO_INTERPOLACION_RELLENO,
    criterio_estricto_tests: bool = CRITERIO_ESTRUCTO_TEST,
    log_msg: Optional[Callable[[str], None]] = None
    
) -> Tuple[dict, pd.Series, list]:
    """
    Selecciona de forma jer√°rquica un tramo representativo de una serie temporal
    para su posterior modelado con ARMA.

    El flujo aplicado considera:
        - Pruebas estad√≠sticas (ADF y KPSS) para detectar estacionariedad.
        - Calidad estructural mediante score PACF.
        - Interpolaci√≥n controlada de NaNs peque√±os si fallan las pruebas anteriores.
        - Heur√≠stico final por similitud de media/varianza si todo lo anterior falla.

    Par√°metros:
    -----------
    serie (pd.Series): Serie temporal original (1D).
    prop_ventana (float): Proporci√≥n inicial del tama√±o de la ventana respecto al total.
    prop_ventana_min (float): Proporci√≥n m√≠nima de la ventana para finalizar b√∫squeda.
    paso (int): Tama√±o del desplazamiento de la ventana en cada iteraci√≥n.
    step_ventana (int): Reducci√≥n de la ventana en cada iteraci√≥n si no hay √©xito.
    max_huecos_interpolables (int): M√°x. nulos consecutivos permitidos para interpolaci√≥n.
    metodo_interpolacion (str): M√©todo de interpolaci√≥n (ej. 'linear', 'spline').
    criterio_estricto_tests (bool): Si True, ambos tests ADF y KPSS deben ser positivos.
    log_msg (Callable, opcional): Funci√≥n para registrar mensajes log.

    Retorna:
    --------
    Tuple[
        dict: Informaci√≥n estad√≠stica del tramo seleccionado.
        pd.Series: Tramo extra√≠do de la serie original.
        list: Lista extendida con motivos de descarte de otros tramos.
    ]
    """

    # Validaciones iniciales
    if not isinstance(serie, pd.Series):
        log_msg("‚ùå 'serie' debe ser una pd.Series")
        raise TypeError("‚ùå 'serie' debe ser una pd.Series")
    if serie.empty:
        log_msg("‚ùå La serie est√° vac√≠a.")
        raise ValueError("‚ùå La serie est√° vac√≠a.")

    # Inicializaci√≥n de variables globales (limpieza de descartes previos)
    global motivos_descartes, motivos_descartes_extendidos
    motivos_descartes.clear()
    motivos_descartes_extendidos.clear()

    # C√°lculos previos para comparativa al final
    L = len(serie)
    media_total = serie.mean()
    var_total = serie.var()
    interpolacion_aplicada = False

    # Primer intento: Tests + Score
    resultado = _buscar_por_tests(
        serie, prop_ventana, prop_ventana_min, paso, step_ventana,
        log_msg=log_msg, criterio_estricto_tests=criterio_estricto_tests
    )

    # Si no encuentra nada v√°lido, probar usando s√≥lo score PACF
    if resultado[2] is None:
        resultado = _buscar_por_score(
            serie, prop_ventana, prop_ventana_min, paso, step_ventana,
            log_msg=log_msg
        )

    # Guardar motivos de descarte antes de intentar interpolar
    descartes_pre_interp = list(motivos_descartes)

    # Interpolaci√≥n si fall√≥ el primer intento
    if resultado[2] is None:
        log_msg("‚ôªÔ∏è Interpolando serie (nulos peque√±os)...")

        serie_interp, tramos_interpolados_log = interpolar_tramos_cortos(
            serie,
            max_huecos=max_huecos_interpolables,
            metodo=metodo_interpolacion,
            log_msg=log_msg
        )
        interpolacion_aplicada = True

        # Intentar b√∫squeda de nuevo sobre la serie interpolada
        motivos_descartes.clear()
        resultado = _buscar_por_tests(
            serie_interp, prop_ventana, prop_ventana_min, paso, step_ventana,
            log_msg=log_msg, criterio_estricto_tests=criterio_estricto_tests
        )
        if resultado[2] is None:
            resultado = _buscar_por_score(
                serie_interp, prop_ventana, prop_ventana_min, paso, step_ventana,
                log_msg=log_msg
            )

    descartes_post_interp = list(motivos_descartes)

    # √öltimo recurso
    if resultado[2] is None:
        motivos_descartes.clear()
        resultado = _buscar_fallback(
            serie, prop_ventana, prop_ventana_min, paso, step_ventana,
            log_msg=log_msg
        )

    index_inicio, index_fin, serie_mejor, mejor_score, adf_p, kpss_p, metodo_seleccion = resultado

    if serie_mejor is None:
        log_msg("‚ùå No se pudo encontrar ning√∫n tramo v√°lido en la serie.")
        raise RuntimeError("‚ùå No se pudo encontrar ning√∫n tramo v√°lido en la serie.")

    # Diagn√≥stico estad√≠stico extra
    try:
        pval_arch = het_arch(serie_mejor.dropna())[1]
        pval_normal = normaltest(serie_mejor.dropna())[1]
    except Exception:
        pval_arch = None
        pval_normal = None

    metadata = {
        "inicio_tramo": int(index_inicio),
        "longitud_tramo": int(index_fin - index_inicio),
        "tama√±o_total_serie": int(L),
        "porcentaje_nans_original": float(serie.isna().mean()),
        "interpolacion_aplicada": interpolacion_aplicada,
        "tramos_interpolados": tramos_interpolados_log if interpolacion_aplicada else None,
        "metodo_seleccion": metodo_seleccion,
        "score": float(mejor_score) if mejor_score != -np.inf else None,
        "media": float(serie_mejor.mean()),
        "varianza": float(serie_mejor.var()),
        "std": float(serie_mejor.std()),
        "adf_p": float(adf_p) if adf_p is not None else None,
        "kpss_p": float(kpss_p) if kpss_p is not None else None,
        "diagnostico_extra": {
            "normalidad_tramo_pval": float(pval_normal) if pval_normal is not None else None,
            "heterocedasticidad_arch_pval": float(pval_arch) if pval_arch is not None else None
        },
        "comparativa_tramo_vs_total": {
            "media_total": float(media_total),
            "media_tramo": float(serie_mejor.mean()),
            "delta_media": float(abs(serie_mejor.mean() - media_total)),
            "var_total": float(var_total),
            "var_tramo": float(serie_mejor.var()),
            "delta_var": float(abs(serie_mejor.var() - var_total))
        },
        "motivo_descartes": {
            "original": dict(Counter(descartes_pre_interp)),
            "post_interpolacion": dict(Counter(descartes_post_interp)) if interpolacion_aplicada else {}
        }
    }

    todos_los_descartes = motivos_descartes_extendidos.copy()
    return metadata, serie_mejor, todos_los_descartes

def mostrar_resultados_modelado(
    metadata: dict,
    tramo: pd.Series,
    descartes_ext: Optional[List[str]] = None,
    incluir_log_extendido: bool = INCLUIR_LOG_EXTENDIDO_TRAMO_MODELOS,
    input_func: Callable[[str], str] = input,
    log_msg: Optional[Callable[[str], None]] = None,
    titulo_grafico: Optional[str] = TITULO_GRAFICO_TRAMO,
    nombre_archivo_grafico: Optional[str] = NOMBRE_ARCHIVO_TRAMO,
    res_dir: str = None,
    modo_auto: bool = MODO_AUTO,
) -> Tuple[str, Optional[str]]:
    """
    Muestra los resultados del modelado tras seleccionar un tramo representativo de la serie.

    Incluye:
        - Informaci√≥n del tramo (inicio, score, m√©todo).
        - Log detallado en formato JSON con estad√≠sticas y diagn√≥stico.
        - Registro extendido de descartes (opcional).
        - Opci√≥n interactiva para visualizar o guardar un gr√°fico del tramo.

    Par√°metros:
        metadata (dict): Diccionario con estad√≠sticas y detalles del tramo seleccionado.
        tramo (pd.Series): Tramo de la serie temporal usado para modelado.
        descartes_ext (List[str], opcional): Lista de motivos extendidos de descarte por tramo.
        incluir_log_extendido (bool): Si True, muestra el log extendido de descartes.
        input_func (Callable): Funci√≥n de entrada (input), mockeable para test.
        log_msg (Callable, opcional): Funci√≥n para loguear los mensajes.
        titulo_grafico (str, opcional): Plantilla para el t√≠tulo del gr√°fico.
        nombre_archivo_grafico (str, opcional): Plantilla para nombre del archivo del gr√°fico.
        res_dir (str): Ruta del directorio donde guardar el gr√°fico.
        modo_auto (bool): Si True, se saltan las preguntas interactivas (modo autom√°tico).

    Retorna:
        Tuple[
            str,              # Log resumen en formato JSON (interno)
            Optional[str]     # Log extendido si aplica, o None
        ]
    """

    # Log b√°sico del tramo seleccionado
    log_msg("‚úÖ Tramo seleccionado:")
    log_msg(f"- Inicio: {metadata['inicio_tramo']}")
    log_msg(f"- Longitud: {metadata['longitud_tramo']}")
    log_msg(f"- Score: {metadata['score']:.4f}")
    log_msg(f"- Motivo de selecci√≥n: {metadata['metodo_seleccion']}")

    # Log completo en formato JSON
    log_msg("üì¶ Metadata del tramo seleccionado:")
    for linea in json.dumps(metadata, indent=4, ensure_ascii=False).splitlines():
        log_msg(linea)
        
    # Log extendido de descartes (si se solicita)
    if incluir_log_extendido and descartes_ext:
        log_msg("\nüìã Log extendido de descartes:")
        if len(descartes_ext) == 0:
            log_msg("- (Sin descartes registrados)")
        else:
            for d in descartes_ext:
                log_msg(f"- {d}")

    # Preguntas para visualizar y guardar gr√°fico
    if preguntar_si_no("¬øDeseas visualizar el tramo seleccionado?", input_func, modo_auto=modo_auto, log_msg=log_msg):
        mostrar = preguntar_si_no(
            "¬øMostrar en pantalla?", input_func,
            modo_auto=modo_auto, respuesta_modo_auto=False, log_msg=log_msg
        )
        guardar = preguntar_si_no(
            "¬øGuardar gr√°fico del tramo en la carpeta de resultados?",
            input_func, modo_auto=modo_auto, log_msg=log_msg
        )

        # Datos del gr√°fico
        inicio = metadata["inicio_tramo"]
        fin = inicio + metadata["longitud_tramo"]
        nombre_base = metadata.get("nombre_base", NOMBRE_LOG_TRAMO_DEFAULT)

        titulo_final = titulo_grafico.format(inicio=inicio, fin=fin) if titulo_grafico else None
        nombre_final = nombre_archivo_grafico.format(
            nombre_base=nombre_base,
            inicio=inicio,
            fin=fin
        ) if nombre_archivo_grafico else None

        # Mostrar/guardar gr√°fico
        plot_serie_inicial(
            serie=tramo,
            titulo=titulo_final,
            guardar=guardar,
            nombre_archivo=nombre_final,
            mostrar=mostrar,
            res_dir=res_dir,
            log_msg=log_msg,
        )

    return

def ejecutar_modelado_arma(
    df: pd.DataFrame,
    input_func: Callable[[str], str] = input,
    prop_ventana: float = MAX_VENTANA,
    prop_ventana_min: float = MIN_VENTANA,
    paso: int = PASO,
    step_ventana: int = STEP_VENTANA,
    incluir_log_extendido_modelo: bool = INCLUIR_LOG_EXTENDIDO_TRAMO_MODELOS,
    titulo_grafico: Optional[str] = TITULO_GRAFICO_TRAMO,
    nombre_archivo_grafico: Optional[str] = NOMBRE_ARCHIVO_TRAMO,
    criterio_estricto_test: bool = CRITERIO_ESTRUCTO_TEST,
    directorio_graficas: str = None,
    log_msg: Optional[Callable[[str], None]] = None,
    modo_auto: bool = MODO_AUTO
) -> Tuple[pd.Series]:
    """
    Ejecuta el proceso completo de selecci√≥n inteligente de un tramo dentro de 
    una serie temporal para su modelado con ARMA, aplicando estrategias jer√°rquicas.

    Este procedimiento:
    - Normaliza la serie para asegurar comparabilidad estructural entre tramos.
    - Eval√∫a distintos tramos mediante tests de estacionariedad (ADF y KPSS).
    - Aplica un sistema de scoring estructural (basado en PACF).
    - Interpola tramos con pocos nulos si es posible.
    - Utiliza una heur√≠stica de fallback si los m√©todos principales no tienen √©xito.
    - Restaura el tramo seleccionado a su escala original.
    - Puede mostrar o guardar visualizaciones del tramo seleccionado.
    - Documenta todos los descartes y decisiones de forma opcional.

    Par√°metros:
    ----------
    df : con una √∫nica columna representando la serie temporal a analizar.
    nombre_archivo_entrada : Nombre base utilizado para los archivos de salida. 
    input_func :Funci√≥n de entrada del usuario (por defecto, `input`).
    prop_ventana : Proporci√≥n inicial de la ventana deslizante respecto al largo total.
    prop_ventana_min : Proporci√≥n m√≠nima permitida para la ventana.
    paso : Cantidad de posiciones que se avanza al deslizar la ventana.
    step_ventana : Paso de reducci√≥n del tama√±o de la ventana al no encontrar tramos v√°lidos.
    incluir_log_extendido_modelo : Si es True, se registran y retornan los descartes detallados.
    titulo_grafico : T√≠tulo del gr√°fico del tramo seleccionado.
    nombre_archivo_grafico : Nombre base del archivo del gr√°fico generado.
    criterio_estricto_test : Si es True, se aplican umbrales m√°s rigurosos para los tests ADF y KPSS.
    directorio_graficas : Carpeta donde guardar los gr√°ficos generados.
    log_msg : Funci√≥n para registrar mensajes del proceso.
    modo_auto : Si es True, omite interacci√≥n con el usuario y aplica decisiones autom√°ticas.

    Retorna:
    -------
    Tuple[pd.Series, Optional[list]]
        - Serie seleccionada como tramo representativo (puede ser vac√≠a si falla).

    """
    # Crear una serie vac√≠a con el mismo tipo de datos que la columna original
    tramo_seleccionado = pd.Series(dtype=df.iloc[:, 0].dtype)

    # Inicializar variables auxiliares
    descartes_ext = None  
    metadata = {}         

    try:
        # Extraer la √∫nica columna del DataFrame 
        serie_original = df.iloc[:, 0]

        # Normalizamos la serie para selecci√≥n de tramo
        media_serie = serie_original.mean()
        std_serie = serie_original.std()
        serie = (serie_original - media_serie) / std_serie


        # Informar al usuario que comienza el proceso de modelado
        log_msg("üß™ Ejecutando selecci√≥n inteligente de tramo...")

        # Ejecutar la l√≥gica principal de b√∫squeda del mejor tramo para modelado ARMA
        metadata, tramo_seleccionado, descartes_ext = seleccionar_tramo_inteligente_para_arma(
            serie=serie,
            prop_ventana=prop_ventana,
            prop_ventana_min=prop_ventana_min,
            paso=paso,
            step_ventana=step_ventana,
            criterio_estricto_tests=criterio_estricto_test,
            log_msg=log_msg
        )
        
        if metadata and "inicio" in metadata and "fin" in metadata:
            tramo_seleccionado = serie.iloc[metadata["inicio"]:metadata["fin"]]

        # Visualizar resultados 
        mostrar_resultados_modelado(
            metadata=metadata,
            tramo=tramo_seleccionado,
            descartes_ext=descartes_ext,
            incluir_log_extendido=incluir_log_extendido_modelo,
            input_func=input_func,
            titulo_grafico=titulo_grafico,
            nombre_archivo_grafico=nombre_archivo_grafico,
            res_dir=directorio_graficas,
            log_msg=log_msg,
            modo_auto=modo_auto
        )

    except Exception as e:
        # Captura cualquier error inesperado en el proceso y lo registra
        log_msg(f"‚ùå Error durante el modelado: {e}")
        tramo_seleccionado = None  

    # Devolver el tramo final seleccionado 
    return tramo_seleccionado
