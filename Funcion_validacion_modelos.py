"""
M√ìDULO: Funcion_validacion_modelos.py

Este m√≥dulo implementa el flujo completo para evaluar, validar y seleccionar modelos ARMA 
previamente entrenados.

Su objetivo es identificar el modelo m√°s robusto y estad√≠sticamente s√≥lido entre m√∫ltiples 
combinaciones (p, q), para la imputaci√≥n de valores nulos en posteriores m√≥dulos.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìå FUNCIONALIDADES PRINCIPALES:

1. Filtrado de modelos convergidos:
   - `seleccionar_modelos_convergidos_desde_df()`: Extrae modelos ARMA v√°lidos desde un DataFrame
     de resultados, descartando los que no tienen par√°metros o residuos.

2. Validaciones estad√≠sticas aplicadas sobre residuos:
   - `realizar_prueba_normalidad()`: Eval√∫a la normalidad con Shapiro-Wilk y D‚ÄôAgostino-Pearson.
   - `realizar_prueba_autocorrelacion()`: Detecta autocorrelaci√≥n con la prueba de Ljung-Box.
   - `realizar_prueba_heterocedasticidad()`: Verifica homocedasticidad con la prueba ARCH.

3. Selecci√≥n jer√°rquica de modelos:
   - `seleccionar_modelo_optimo()`: Aplica una l√≥gica de priorizaci√≥n:
        1) validaci√≥n completa,
        2) validaci√≥n parcial (solo autocorrelaci√≥n y heterocedasticidad),
        3) mejor AIC o BIC disponible.

4. Evaluaci√≥n orquestada:
   - `seleccionar_mejor_modelo_desde_df()`: Eval√∫a un conjunto de modelos, aplica validaciones
     y selecciona el m√°s adecuado con logs extendidos y resumen.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RETORNO FINAL:
   - Modelo escogido para la imputaci√≥n. 
"""


# =============================================================
# üß± 1. LIBRER√çAS EST√ÅNDAR
# =============================================================

from typing import Any, Dict, List, Optional, Tuple, Callable

# =============================================================
# üì¶ 2. LIBRER√çAS DE TERCEROS
# =============================================================

import numpy as np
import pandas as pd
from scipy.stats import normaltest, shapiro
from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch

# =============================================================
# ‚öôÔ∏è 3. CONFIGURACI√ìN GLOBAL (config.py)
# =============================================================

from config import (
    # Umbrales de significancia
    ALPHA_TESTS_NORMALIDAD,
    ALPHA_TESTS_AUTOCORR,
    ALPHA_TESTS_HETEROCED,

    # Par√°metros para pruebas estad√≠sticas
    LIMITE_SHAPIRO,
    FALLOS_MAXIMOS_NORMALIDAD,
    MAX_LAGS_LB,
    MIN_LAGS_LB,

    # Criterio de selecci√≥n
    CRITERIO_SELECCION_MODELO,

    # Activaci√≥n de tests
    USAR_TESTS_NORMALIDAD,
    USAR_TESTS_AUTOCORRELACION,
    USAR_TESTS_HETEROCEDASTICIDAD,
)

def seleccionar_modelos_convergidos_desde_df(
    df_modelos: pd.DataFrame,
    log_msg: Optional[Callable[[str], None]] = None,
) -> List[Tuple[str, Tuple[int, int], Dict[str, Any]]]:
    """
    Extrae modelos ARMA convergidos y v√°lidos desde un DataFrame de resultados.

    Esta funci√≥n filtra modelos cuya convergencia fue exitosa (`converged == True`), su fase es 'refined'
    y que contienen tanto par√°metros como residuos no nulos. El objetivo es preparar
    una lista de modelos aptos para evaluaci√≥n posterior (e.g. validaci√≥n o selecci√≥n final).

    Par√°metros:
        df_modelos (pd.DataFrame): DataFrame con resultados del grid search ARMA.
            Debe contener al menos las columnas: 'p', 'q', 'params', 'residuals', 'phase', 'converged'.
            Columnas opcionales: 'nombre_serie', 'aic', 'bic'.

        log_msg (Callable, opcional): Funci√≥n para registrar mensajes (log). Si no se proporciona,
            los errores se omitir√°n silenciosamente.

    Retorna:
        List[Tuple[str, Tuple[int, int], Dict[str, Any]]]:
            Lista de modelos v√°lidos en el formato:
            - nombre_serie (str): Identificador del modelo o serie.
            - (p, q): Orden del modelo ARMA.
            - dict: Informaci√≥n adicional del modelo, incluyendo:
                - params (List[float]): Coeficientes del modelo.
                - residuals (List[float]): Residuos del ajuste.
                - phase (str): Fase de entrenamiento (ej. 'initial', 'refined').
                - aic (float): AIC del modelo (si est√° disponible).
                - bic (float): BIC del modelo (si est√° disponible).
                - orden (Tuple[int, int]): Redundante, por compatibilidad.
    """
    modelos = []

    # Filtrar solo modelos convergidos y de fase 'refined'
    df_ok = df_modelos[
        (df_modelos["converged"] == True) &
        (df_modelos["phase"] == "refined")
    ]

    for _, row in df_ok.iterrows():
        try:
            # ‚îÄ Extracci√≥n b√°sica de informaci√≥n ‚îÄ
            p = int(row["p"])
            q = int(row["q"])
            nombre = row.get("nombre_serie", f"modelo_{p}_{q}")
            residuals = row.get("residuals")
            params = row.get("params")
            phase = row.get("phase", "unknown")
            aic = row.get("aic") if pd.notnull(row.get("aic")) else None
            bic = row.get("bic") if pd.notnull(row.get("bic")) else None

            # ‚îÄ Validaci√≥n: deben existir residuos y par√°metros ‚îÄ
            if residuals is None or params is None:
                log_msg(f"‚ö†Ô∏è Modelo ({p},{q}) omitido: faltan residuos o par√°metros.")
                continue

            # ‚îÄ Modelo v√°lido: se a√±ade al listado ‚îÄ
            modelos.append((
                nombre,
                (p, q),
                {
                    "p": p,
                    "q": q,
                    "params": params,
                    "residuals": residuals,
                    "phase": phase,
                    "aic": aic,
                    "bic": bic,
                    "orden": (p, q)
                }
            ))

        except Exception as e:
            log_msg(f"‚ö†Ô∏è Error al procesar modelo ({row.get('p')},{row.get('q')}): {e}")

    return modelos

def realizar_prueba_normalidad(
    resid: np.ndarray,
    alpha: float = ALPHA_TESTS_NORMALIDAD,
    fallos_maximos: int = FALLOS_MAXIMOS_NORMALIDAD,
    log_msg: Optional[Callable[[str], None]] = None
) -> Tuple[Dict[str, Any], bool]:
    """
    Eval√∫a la normalidad de los residuos de un modelo ARMA mediante dos pruebas estad√≠sticas:

    1. **Shapiro-Wilk**: adecuada para muestras peque√±as o moderadas (< 5000 elementos).
    2. **D‚ÄôAgostino-Pearson (normaltest)**: recomendada para tama√±os grandes.

    Ambas pruebas retornan un p-valor. Si dicho p-valor es menor que `alpha`,
    se rechaza la hip√≥tesis de normalidad.

    El vector de residuos se considera "normal" si la cantidad de pruebas con p-valor
    < `alpha` no excede el l√≠mite `fallos_maximos`.

    Par√°metros:
        resid (np.ndarray): Residuos del modelo ARMA.
        alpha (float): Nivel de significancia para rechazar normalidad.
        fallos_maximos (int): M√°ximo de pruebas que pueden fallar para aceptar normalidad.
        log_msg (Callable, opcional): Funci√≥n de log para registrar advertencias o errores.

    Retorna:
        Tuple[Dict[str, Any], bool]:
            - Dict: Resultados de cada prueba (p-valores y errores si ocurren).
                Claves posibles: 'shapiro', 'dagostino', 'shapiro_error', 'dagostino_error'.
            - bool: True si los residuos pueden considerarse normales, False en caso contrario.
    """
    resultado = {}

    try:
        # Validaci√≥n de entrada
        if len(resid) == 0:
            log_msg("El vector de residuos est√° vac√≠o.")
            raise ValueError("El vector de residuos est√° vac√≠o.")

        # Prueba de Shapiro-Wilk (mejor en muestras peque√±as-medias)
        try:
            if len(resid) >= LIMITE_SHAPIRO:
                p_shapiro = shapiro(resid[:LIMITE_SHAPIRO])[1]  # limitar tama√±o
            else:
                p_shapiro = shapiro(resid)[1]
            resultado["shapiro"] = float(p_shapiro)
        except Exception as e:
            resultado["shapiro"] = None
            resultado["shapiro_error"] = str(e)
            p_shapiro = 1.0  # se considera como no fallida

        # Prueba de D‚ÄôAgostino-Pearson (m√°s robusta en grandes muestras)
        try:
            p_dagostino = normaltest(resid)[1]
            resultado["dagostino"] = float(p_dagostino)
        except Exception as e:
            resultado["dagostino"] = None
            resultado["dagostino_error"] = str(e)
            p_dagostino = 1.0  # no penaliza

        # üîç Evaluaci√≥n de n√∫mero de fallos seg√∫n p-valores
        fallos = sum(
            p < alpha for p in [p for p in [p_shapiro, p_dagostino] if p is not None]
        )
        es_normal = fallos <= fallos_maximos

        return resultado, es_normal

    except Exception as e:
        return {"error": str(e)}, False

def realizar_prueba_autocorrelacion(
    resid: np.ndarray,
    alpha: float = ALPHA_TESTS_AUTOCORR,
    log_msg: Optional[Callable[[str], None]] = None
) -> Tuple[Dict[str, Any], bool]:
    """
    Eval√∫a la autocorrelaci√≥n en los residuos de un modelo ARMA mediante la prueba de Ljung-Box.

    Esta prueba verifica si los residuos son independientes (no autocorrelados) hasta un cierto n√∫mero de lags.
    El n√∫mero de lags se ajusta din√°micamente en funci√≥n del tama√±o de la muestra, respetando los l√≠mites
    definidos por configuraci√≥n (`MIN_LAGS_LB`, `MAX_LAGS_LB`).

    Si el p-valor del √∫ltimo lag evaluado es mayor o igual a `alpha`, se considera que no hay evidencia significativa
    de autocorrelaci√≥n ‚Üí se aceptan los residuos como independientes.

    Par√°metros:
        resid (np.ndarray): Vector de residuos del modelo ARMA.
        alpha (float): Nivel de significancia para la prueba. Si p < alpha, se rechaza la independencia.
        log_msg (Callable, opcional): Funci√≥n para registrar mensajes en log o consola.

    Retorna:
        Tuple[Dict[str, Any], bool]:
            - dict: {'ljungbox_p': valor_p_final} o {"error": mensaje}.
            - bool: True si no hay autocorrelaci√≥n (p >= alpha); False si se rechaza la independencia.
    """
    try:
        n = len(resid)

        # üîí Validaci√≥n: longitud m√≠nima para aplicar la prueba
        if n < 10:
            log_msg("La serie de residuos es demasiado corta para Ljung-Box.")
            raise ValueError("La serie de residuos es demasiado corta para Ljung-Box.")

        # üßÆ Determinar n√∫mero de lags (entre MIN y MAX definidos por configuraci√≥n)
        max_lags = min(MAX_LAGS_LB, max(MIN_LAGS_LB, n // 10))

        # üß™ Ejecutar Ljung-Box para detectar autocorrelaci√≥n
        resultado = acorr_ljungbox(
            resid,
            lags=range(1, max_lags + 1),
            return_df=True
        )

        # üîç Evaluar p-valor del √∫ltimo lag (m√°s estricto)
        p_ljung = resultado["lb_pvalue"].iloc[-1]
        pasa_test = p_ljung >= alpha  # True ‚Üí no hay autocorrelaci√≥n significativa

        return {"ljungbox_p": float(p_ljung)}, pasa_test

    except Exception as e:
        return {"error": str(e)}, False

def realizar_prueba_heterocedasticidad(
    resid: np.ndarray,
    alpha: float = ALPHA_TESTS_HETEROCED,
    log_msg: Optional[Callable[[str], None]] = None,
) -> Tuple[Dict[str, Any], bool]:
    """
    Eval√∫a la heterocedasticidad en los residuos de un modelo mediante la prueba ARCH de Engle.

    La heterocedasticidad implica que la varianza de los errores cambia en el tiempo, lo cual
    viola los supuestos de muchos modelos estad√≠sticos. Esta funci√≥n verifica si los residuos
    presentan comportamiento ARCH (varianza condicional no constante).

    Si el p-valor obtenido es mayor o igual a `alpha`, se acepta homocedasticidad
    (varianza constante), lo que es deseable.

    Par√°metros:
        resid (np.ndarray): Vector de residuos del modelo.
        alpha (float): Nivel de significancia para la prueba. Si p < alpha, se rechaza homocedasticidad.
        log_msg (Callable, opcional): Funci√≥n para mostrar mensajes o registrar logs.

    Retorna:
        Tuple[Dict[str, Any], bool]:
            - dict: {'arch_pval': valor_p_arch} o {"error": str} si falla.
            - bool: True si los residuos se consideran homoced√°sticos; False si hay evidencia de heterocedasticidad.
    """

    try:
        # Validaci√≥n de longitud m√≠nima
        if len(resid) < 10:
            raise ValueError("La serie de residuos es demasiado corta para evaluar heterocedasticidad.")

        # Ejecutar prueba ARCH de Engle (detecta varianza no constante)
        _, pval_arch, _, _ = het_arch(resid)

        resultado = {"arch_pval": float(pval_arch)}

        # Decisi√≥n: si p >= alpha, no hay evidencia de heterocedasticidad
        pasa_test = pval_arch >= alpha

        return resultado, pasa_test

    except Exception as e:
        # En caso de error, registrar y retornar resultado negativo
        return {"error": str(e)}, False

def seleccionar_modelo_optimo(
    resultados: List[Tuple[Dict[str, Any], Optional[float], Optional[float], Tuple[int, int], Dict[str, Any], bool, str]],
    criterio: str = CRITERIO_SELECCION_MODELO,
    usar_normalidad: bool = USAR_TESTS_NORMALIDAD,
    usar_autocorrelacion: bool = USAR_TESTS_AUTOCORRELACION,
    usar_heterocedasticidad: bool = USAR_TESTS_HETEROCEDASTICIDAD,
    log_msg: Optional[Callable[[str], None]] = None,
) -> Tuple[Optional[Dict[str, Any]], str]:
    """
    Selecciona el modelo ARMA √≥ptimo a partir de una lista de resultados evaluados estad√≠sticamente.

    La selecci√≥n sigue una jerarqu√≠a de preferencia:
    1. Modelos que validan todas las pruebas activadas (normalidad, autocorrelaci√≥n, heterocedasticidad).
    2. Modelos que validan al menos autocorrelaci√≥n y heterocedasticidad (si est√°n activadas).
    3. Modelo con el mejor valor del criterio (AIC o BIC), sin importar validaciones.

    A partir de la versi√≥n actual, los modelos se comparan seg√∫n un **score total ponderado**
    que combina la m√©trica seleccionada (AIC o BIC) normalizada y penalizaciones proporcionales
    a los p-valores de los tests activados:

        score_total = 
            w_criterio √ó (AIC o BIC normalizado)
          + w_norm     √ó penalizaci√≥n de normalidad (si aplica)
          + w_auto     √ó penalizaci√≥n de autocorrelaci√≥n
          + w_heter    √ó penalizaci√≥n de heterocedasticidad

    La normalizaci√≥n se realiza min-max entre los modelos v√°lidos.
    Los pesos (`w_*`) pueden ajustarse dentro del bloque correspondiente.

    Par√°metros:
        resultados (List[Tuple]): Lista de tuplas con resultados por modelo:
            - modelo_dict (Dict): Informaci√≥n del modelo.
            - aic (float | None)
            - bic (float | None)
            - orden (Tuple[int, int])
            - tests (Dict): Resultados de validaciones estad√≠sticas.
            - validado (bool): Indicador si pasa validaciones.
            - origen (str): Nombre/identificador del modelo.

        criterio (str): M√©trica principal de selecci√≥n ('aic' o 'bic').
        usar_normalidad (bool): Si evaluar test de normalidad.
        usar_autocorrelacion (bool): Si evaluar test de autocorrelaci√≥n (Ljung-Box).
        usar_heterocedasticidad (bool): Si evaluar test de heterocedasticidad (ARCH).
        log_msg (Callable): Funci√≥n opcional para registrar mensajes (logger).

    Retorna:
        Tuple:
            - modelo_dict (Dict): Modelo seleccionado (o None si no hay candidato).
            - log_texto (str): Resumen textual explicativo del modelo y su validaci√≥n.
    """

    def resumen(modelo, validacion: str) -> str:
        """
        Genera un resumen textual explicativo con los resultados de validaci√≥n estad√≠stica
        del modelo seleccionado (normalidad, autocorrelaci√≥n, heterocedasticidad).

        Eval√∫a si el modelo cumple con los supuestos deseables en los residuos y documenta
        los resultados test por test, indicando si se pasan, se omiten o est√°n desactivados.

        Par√°metros:
            modelo (tuple): Tupla con informaci√≥n estructurada del modelo:
                - modelo_dict: dict con info clave ('params', 'residuals', etc.).
                - aic (float): M√©trica AIC del modelo.
                - bic (float): M√©trica BIC del modelo.
                - orden (tuple): Par (p, q).
                - tests (dict): Resultados de los tests estad√≠sticos.
                - validado (bool): Estado de validaci√≥n.
                - origen (str): M√©todo de selecci√≥n o fuente del modelo.

            validacion (str): Estado de validaci√≥n ('S√≠', 'Parcialmente', 'No').

        Retorna:
            str: Cadena de texto con explicaci√≥n detallada y resultados de cada prueba.
        """
        # Introducci√≥n a los criterios evaluados
        txt = "\n=== CRITERIOS DE VALIDACI√ìN ===\n"
        txt += "- Normalidad: residuos deben seguir una distribuci√≥n normal (Shapiro, D'Agostino)\n"
        txt += "- Autocorrelaci√≥n: residuos no deben tener autocorrelaci√≥n (Ljung-Box)\n"
        txt += "- Heterocedasticidad: varianza constante en el tiempo (ARCH)\n"

        # Detalles del modelo y m√©tricas
        txt += "\n--- SELECCI√ìN DEL MODELO ---\n"
        txt += f"Origen: {modelo[6]}\n"
        txt += f"Orden (p, q): {modelo[3]}\n"
        txt += f"AIC: {modelo[1]:.4f}\n"
        txt += f"BIC: {modelo[2]:.4f}\n"
        txt += f"Validado: {validacion}\n"
        txt += "Resultados de tests:\n"

        # Establecer qu√© tests se deben tener en cuenta seg√∫n el estado de validaci√≥n
        if validacion == "S√≠":
            tests_usados = {
                "normalidad": USAR_TESTS_NORMALIDAD,
                "autocorrelacion": USAR_TESTS_AUTOCORRELACION,
                "heterocedasticidad": USAR_TESTS_HETEROCEDASTICIDAD
            }
        elif validacion == "Parcialmente":
            # En fase relajada se ignora la normalidad
            tests_usados = {
                "normalidad": False,
                "autocorrelacion": USAR_TESTS_AUTOCORRELACION,
                "heterocedasticidad": USAR_TESTS_HETEROCEDASTICIDAD
            }
        else:
            # En modelos no validados, se reportan todos seg√∫n configuraci√≥n global
            tests_usados = {
                "normalidad": USAR_TESTS_NORMALIDAD,
                "autocorrelacion": USAR_TESTS_AUTOCORRELACION,
                "heterocedasticidad": USAR_TESTS_HETEROCEDASTICIDAD
            }

        # Evaluar y agregar resultados de cada test
        for test, resultados_test in modelo[4].items():
            if test == "error":
                continue  # Ignorar campo de error global

            resumen_test = dict(resultados_test) if isinstance(resultados_test, dict) else {}

            # ‚îÄ Normalidad ‚îÄ
            if test == "normalidad":
                if USAR_TESTS_NORMALIDAD:
                    if tests_usados[test]:
                        # Solo se aprueba si todos los p-valores son mayores al umbral
                        ok = all(
                            isinstance(p, (float, int)) and p > ALPHA_TESTS_NORMALIDAD
                            for p in resumen_test.values()
                            if not isinstance(p, str)
                        )
                        resumen_test["‚úîÔ∏è"] = ok
                    else:
                        resumen_test["info"] = "omitido (fase relajada)"
                else:
                    resumen_test["info"] = "test desactivado"

            # ‚îÄ Autocorrelaci√≥n ‚îÄ
            elif test == "autocorrelacion":
                if USAR_TESTS_AUTOCORRELACION:
                    if tests_usados[test]:
                        resumen_test["‚úîÔ∏è"] = resumen_test.get("ljungbox_p", 0) > ALPHA_TESTS_AUTOCORR
                    else:
                        resumen_test["info"] = "omitido (fase relajada)"
                else:
                    resumen_test["info"] = "test desactivado"

            # ‚îÄ Heterocedasticidad ‚îÄ
            elif test == "heterocedasticidad":
                if USAR_TESTS_HETEROCEDASTICIDAD:
                    if tests_usados[test]:
                        resumen_test["‚úîÔ∏è"] = resumen_test.get("arch_pval", 0) > ALPHA_TESTS_HETEROCED
                    else:
                        resumen_test["info"] = "omitido (fase relajada)"
                else:
                    resumen_test["info"] = "test desactivado"

            # A√±adir al resumen textual
            txt += f"  {test}: {resumen_test}\n"

        return txt

    # Determinar el √≠ndice de la m√©trica en la tupla
    key_map = {"aic": 1, "bic": 2}
    criterio_idx = key_map.get(criterio.lower(), 1)

    # Modelos que validan todas las pruebas activadas
    modelos_validos = []
    for r in resultados:
        tests = r[4]
        validado = True

        if usar_normalidad:
            normalidad = tests.get("normalidad", {})
            validado &= all(
                isinstance(p, (float, int)) and p > ALPHA_TESTS_NORMALIDAD
                for p in normalidad.values()
            )

        if usar_autocorrelacion:
            validado &= tests.get("autocorrelacion", {}).get("ljungbox_p", 0) > ALPHA_TESTS_AUTOCORR

        if usar_heterocedasticidad:
            validado &= tests.get("heterocedasticidad", {}).get("arch_pval", 0) > ALPHA_TESTS_HETEROCED

        if validado:
            modelos_validos.append(r)


    # Filtrar modelos con criterio definido
    modelos_validos = [r for r in modelos_validos if r[criterio_idx] is not None]

    if modelos_validos:
        # Definici√≥n de pesos para ponderar AIC/BIC y los tests estad√≠sticos
        w_criterio   = 0.4
        w_norm  = 0.2
        w_auto  = 0.2
        w_heter = 0.2
        # Normalizaci√≥n min-max del AIC/BIC
        valores_criterio = [r[criterio_idx] for r in modelos_validos]
        min_val, max_val = min(valores_criterio), max(valores_criterio)
        rango_val = max_val - min_val if max_val != min_val else 1.0

        def score_total(x):
            """
        Calcula un score total ponderado para un modelo dado.

        Combina la m√©trica principal (AIC/BIC) normalizada y las penalizaciones que resultan de los resultados de las pruebas estad√≠sticas
        y de acuerdo a la ponderaci√≥n. 

        Cuanto menor es el score, mejor es el modelo.

        Par√°metros:
            x (tuple): Tupla con la informaci√≥n del modelo evaluado.

        Retorna:
            float: Score total del modelo (valor a minimizar).
            """
            norm_crit = (x[criterio_idx] - min_val) / rango_val

            penal_norm = sum(
                1.0 - p if isinstance(p, (int, float)) else 1.0
                for p in x[4].get("normalidad", {}).values()
                if not isinstance(p, str)
            )

            penal_auto = (
                1.0 - x[4].get("autocorrelacion", {}).get("ljungbox_p", 0)
                if isinstance(x[4].get("autocorrelacion", {}).get("ljungbox_p", 0), (int, float))
                else 1.0
            )

            penal_heter = (
                1.0 - x[4].get("heterocedasticidad", {}).get("arch_pval", 0)
                if isinstance(x[4].get("heterocedasticidad", {}).get("arch_pval", 0), (int, float))
                else 1.0
            )

            return (
                w_criterio   * norm_crit +
                w_norm  * penal_norm +
                w_auto  * penal_auto +
                w_heter * penal_heter
            )

        modelo_final = min(modelos_validos, key=score_total)
        score_val = score_total(modelo_final)

        log_msg(
            f"‚úÖ Modelo validado completo: {modelo_final[6]} orden={modelo_final[3]} "
            f"{criterio.upper()}={modelo_final[criterio_idx]:.2f} | Score total ponderado={score_val:.4f}"
        )
        return modelo_final[0], resumen(modelo_final, "S√≠")

    # Modelos parcialmente validados (sin normalidad)
    modelos_relajados = []
    for r in resultados:
        tests = r[4]
        auto_ok = True
        hetero_ok = True

        if usar_autocorrelacion:
            auto_ok = tests.get("autocorrelacion", {}).get("ljungbox_p", 0) > ALPHA_TESTS_AUTOCORR
        if usar_heterocedasticidad:
            hetero_ok = tests.get("heterocedasticidad", {}).get("arch_pval", 0) > ALPHA_TESTS_HETEROCED

        if auto_ok and hetero_ok:
            modelos_relajados.append(r)

    if modelos_relajados:
        # Ponderaci√≥n de los criterios de validaci√≥n para los modelos validados parcialmente
        w_criterio   = 0.4
        w_auto  = 0.3
        w_heter = 0.3

        # Normalizaci√≥n min-max del AIC/BIC
        valores_criterio = [r[criterio_idx] for r in modelos_relajados]
        min_val, max_val = min(valores_criterio), max(valores_criterio)
        rango_val = max_val - min_val if max_val != min_val else 1.0

        def score_relajado(x):
            """
        Calcula un score total ponderado para un modelo dado, sin tener en cuenta la parte de normalidad en los residuos.

        Cuanto menor es el score, mejor es el modelo.

        Par√°metros:
            x (tuple): Tupla con la informaci√≥n del modelo evaluado.

        Retorna:
            float: Score total del modelo (valor a minimizar).
            """
            norm_crit = (x[criterio_idx] - min_val) / rango_val

            penal_auto = (
                1.0 - x[4].get("autocorrelacion", {}).get("ljungbox_p", 0)
                if isinstance(x[4].get("autocorrelacion", {}).get("ljungbox_p", 0), (int, float))
                else 1.0
            )

            penal_heter = (
                1.0 - x[4].get("heterocedasticidad", {}).get("arch_pval", 0)
                if isinstance(x[4].get("heterocedasticidad", {}).get("arch_pval", 0), (int, float))
                else 1.0
            )

            return (
                w_criterio   * norm_crit +
                w_auto  * penal_auto +
                w_heter * penal_heter
            )

        modelo_final = min(modelos_relajados, key=score_relajado)
        score_total= score_relajado(modelo_final)
        log_msg(
            f"‚ö†Ô∏è Modelo parcialmente validado: {modelo_final[6]} orden={modelo_final[3]} "
            f"{criterio.upper()}={modelo_final[criterio_idx]:.2f} | Score total ponderado={score_total:.4f}"
        )
        return modelo_final[0], resumen(modelo_final, "Parcialmente")

    # Selecci√≥n por AIC/BIC, sin validaci√≥n
    modelos_con_criterio = [r for r in resultados if r[criterio_idx] is not None]
    if modelos_con_criterio:
        modelo_final = min(modelos_con_criterio, key=lambda x: x[criterio_idx])
        log_msg(f"‚ö†Ô∏è Modelo por puro criterio: {modelo_final[6]} orden={modelo_final[3]} {criterio.upper()}={modelo_final[criterio_idx]:.2f}")
        return modelo_final[0], resumen(modelo_final, "No")

    # Nada v√°lido
    log_msg("‚ùå No se encontr√≥ ning√∫n modelo con datos v√°lidos.")
    return None, "‚ùå No se encontr√≥ ning√∫n modelo v√°lido para seleccionar."

def seleccionar_mejor_modelo_desde_df(
    carpeta_modelos: pd.DataFrame,
    criterio: str = CRITERIO_SELECCION_MODELO,
    usar_normalidad: bool = USAR_TESTS_NORMALIDAD,
    usar_autocorrelacion: bool = USAR_TESTS_AUTOCORRELACION,
    usar_heterocedasticidad: bool = USAR_TESTS_HETEROCEDASTICIDAD,
    fallos_maximos: int = FALLOS_MAXIMOS_NORMALIDAD,
    alpha: float = ALPHA_TESTS_NORMALIDAD,
    alpha_auto: float = ALPHA_TESTS_AUTOCORR,
    alpha_heter: float = ALPHA_TESTS_HETEROCED,
    log_msg: Optional[Callable[[str], None]] = None,
) -> Optional[Dict[str, Any]]:
    """
    Eval√∫a un conjunto de modelos ARMA desde un DataFrame y selecciona el mejor modelo disponible.

    Se aplican validaciones estad√≠sticas sobre los residuos (normalidad, autocorrelaci√≥n, heterocedasticidad)
    seg√∫n configuraci√≥n, y se selecciona el modelo que cumpla las condiciones m√°s estrictas posibles.

    Adem√°s, para modelos que pasan las validaciones, se calcula un score total ponderado que combina 
    el criterio de informaci√≥n (AIC/BIC) con penalizaciones por resultados en los tests estad√≠sticos.

    Prioridades:
        1. Modelos que pasan todas las validaciones activadas ‚Üí se selecciona el de menor score ponderado.
        2. Modelos que pasan autocorrelaci√≥n y heterocedasticidad (fase relajada).
        3. Modelo con el mejor AIC/BIC, aunque no pase validaciones.

    Par√°metros:
        carpeta_modelos (pd.DataFrame): Modelos entrenados con columnas como 'p', 'q', 'residuals', etc.
        criterio (str): Criterio de selecci√≥n: 'aic' o 'bic'.
        usar_normalidad (bool): Activar prueba de normalidad.
        usar_autocorrelacion (bool): Activar prueba de autocorrelaci√≥n.
        usar_heterocedasticidad (bool): Activar prueba de heterocedasticidad.
        fallos_maximos (int): Fallos permitidos para considerar normalidad v√°lida.
        alpha (float): Nivel de significancia para normalidad.
        alpha_auto (float): Nivel de significancia para autocorrelaci√≥n.
        alpha_heter (float): Nivel de significancia para heterocedasticidad.
        log_msg (Callable, opcional): Funci√≥n logger para imprimir mensajes.

    Retorna:
            - Modelo seleccionado (dict) o None.
    """
    resultados = []
    log_msg("üîç Iniciando selecci√≥n del mejor modelo desde DataFrame...")

    modelos = seleccionar_modelos_convergidos_desde_df(carpeta_modelos,log_msg=log_msg)
    log_msg(f"üì¶ Modelos convergidos encontrados: {len(modelos)}")

    for nombre_serie, (p, q), model_data in modelos:
        pruebas = {
            "normalidad": {},
            "autocorrelacion": {},
            "heterocedasticidad": {},
            "error": None
        }
        valido = True

        try:
            resid = np.array(model_data["residuals"])
            aic = model_data["aic"]
            bic = model_data["bic"]

            log_msg(f"\n‚û°Ô∏è Evaluando modelo: {nombre_serie} | Orden: ({p},{q})")
            log_msg(f"   AIC: {aic} | BIC: {bic}")
            log_msg(f"   Residuos: {len(resid)} observaciones")

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Normalidad
            if usar_normalidad:
                resultado, es_valido = realizar_prueba_normalidad(resid, alpha=alpha, fallos_maximos=fallos_maximos,log_msg=log_msg)
                pruebas["normalidad"] = resultado
                if not es_valido:
                    valido = False
                log_msg(f"   üî¨ Normalidad: {resultado} | {'‚úÖ' if es_valido else '‚ùå'}")

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Autocorrelaci√≥n
            if usar_autocorrelacion:
                resultado, es_valido = realizar_prueba_autocorrelacion(resid, alpha=alpha_auto,log_msg=log_msg)
                pruebas["autocorrelacion"] = resultado
                if not es_valido:
                    valido = False
                log_msg(f"   üîÑ Autocorrelaci√≥n: {resultado} | {'‚úÖ' if es_valido else '‚ùå'}")

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Heterocedasticidad
            if usar_heterocedasticidad:
                resultado, es_valido = realizar_prueba_heterocedasticidad(resid, alpha=alpha_heter,log_msg=log_msg)
                pruebas["heterocedasticidad"] = resultado
                if not es_valido:
                    valido = False
                log_msg(f"   üìâ Heterocedasticidad: {resultado} | {'‚úÖ' if es_valido else '‚ùå'}")

            resultados.append((model_data, aic, bic, (p, q), pruebas, valido, nombre_serie))

        except Exception as e:
            log_msg(f"‚ö†Ô∏è Error procesando modelo {nombre_serie} ({p},{q}): {e}")
            pruebas["error"] = str(e)
            resultados.append((model_data, None, None, (p, q), pruebas, False, nombre_serie))

    log_msg(f"\nüìä Total modelos evaluados: {len(resultados)}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Selecci√≥n del modelo √≥ptimo
    modelo_sel, log_resumen = seleccionar_modelo_optimo(
        resultados=resultados,
        criterio=criterio,
        usar_normalidad=usar_normalidad,
        usar_autocorrelacion=usar_autocorrelacion,
        usar_heterocedasticidad=usar_heterocedasticidad,
        log_msg=log_msg
    )

    log_msg(log_resumen)

    return modelo_sel

